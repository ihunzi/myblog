# tensorflow2è¿›é˜¶

[TOC]

## åˆ†å‰²ä¸åˆå¹¶

### åˆå¹¶

`concat`

é€šè¿‡`tf.concat(tensors, axis)`å‡½æ•°æ‹¼æ¥å¼ é‡ï¼Œå…¶ä¸­å‚æ•°tensors ä¿å­˜äº†æ‰€æœ‰éœ€è¦åˆå¹¶çš„å¼ é‡Listï¼Œaxis å‚æ•°æŒ‡å®šéœ€è¦åˆå¹¶çš„ç»´åº¦ç´¢å¼•ã€‚

è®¾ä¸€ä¸ªtensorä¸ºï¼ša = [6, 35, 8]ï¼Œå…·ä½“å«ä¹‰æ˜¯ï¼š6ä¸ªç­çº§ï¼Œæ¯ä¸ªç­çº§35ä¸ªå­¦ç”Ÿï¼Œ 8é—¨å­¦ç§‘

* **æ­¤æ—¶éœ€è¦Aæ”¶é›†4ä¸ªç­çš„æ•°æ®ï¼ŒBæ”¶é›†2ä¸ªç­çš„æ•°æ®ï¼Œå¹¶å°†Aå’ŒBçš„æ•°æ®åˆå¹¶èµ·æ¥äº¤ç»™Cã€‚**

```python
a = tf.ones([4, 35, 8])
b = tf.ones([2, 35, 8])
c = tf.concat([a, b], axis=0)

c.shape
TensorShape([6, 35, 8])
```

* **æ­¤æ—¶éœ€è¦Aæ”¶é›†4ä¸ªç­æ¯ä¸ªç­32ä¸ªåŒå­¦çš„æ•°æ®ï¼ŒBæ”¶é›†4ä¸ªç­æ¯ä¸ªç­3ä¸ªåŒå­¦çš„æ•°æ®ï¼Œå¹¶å°†Aå’ŒBçš„æ•°æ®åˆå¹¶èµ·æ¥äº¤ç»™Cã€‚**

```python
a = tf.ones([4, 32, 8])
b = tf.ones([4, 3, 8])
c = tf.concat([a, b], axis=1)

c.shape
TensorShape([4, 35, 8])
```

*è¦åˆå¹¶çš„ç»´åº¦å¯ä»¥ä¸ç›¸ç­‰ï¼Œå…¶ä»–ç»´åº¦éƒ½è¦ç›¸ç­‰*

### å †å 

`stack`

å‡è®¾å­¦æ ¡A[4, 35, 8]ï¼Œå­¦æ ¡B[4, 35, 8]ï¼›æŠŠä¸¤ä¸ªå­¦æ ¡çš„æ•°æ®åˆå¹¶åˆ°ä¸€èµ·å˜æˆ[2, 4, 35, 8]

```python
a = tf.ones([4, 35, 8])
b = tf.ones([4, 35, 8])

c = tf.stack([a, b], axis=0)
d = tf.stack([a, b], axis=3)

c.shape
TensorShape([2, 4, 35, 8])
d.shape
TensorShape([4, 35, 8, 2])
```

*æ‰€æœ‰çš„ç»´åº¦éƒ½è¦å®Œå…¨ç›¸ç­‰*

### åˆ‡å‰²

* `unstack`

ä»¥ä¸Šé¢c = [2, 4, 35, 8]ä¸ºä¾‹

```python
aa, bb = tf.unstack(c, axis=0)
aa.shape, bb.shape
TensorShape([4, 35, 8]), TensorShape([4, 35, 8])

res = tf.unstack(c, axis=3)
res[0].shape, res[1].shape...res[7].shape
TensorShape([2, 4, 35])...
```

è¦åˆ†å‰²çš„è½´ä¸Šæ˜¯å¤šå°‘ï¼Œå°±åˆ†å‰²æˆå¤šå°‘ä¸ªtensorã€‚æ¯”å¦‚ä¸Šé¢çš„axis=3ä¸º8ï¼Œå°±åˆ†å‰²æˆä¸€ä¸ªé•¿åº¦ä¸º8çš„Listï¼Œæ¯ä¸ªlistçš„shapeå¦‚ä¸Š

* `split`

`tf.split(x, num_or_size_splits, axis)`å‚æ•°æ„ä¹‰å¦‚ä¸‹

![image-20210806153325555](https://gitee.com/ihunzi/images/raw/master/blog/image-20210806153325555.png)

------

## æ•°æ®ç»Ÿè®¡

### èŒƒæ•°

`tf.norm(x, ord, axis)`

å…¶ä¸­å‚æ•°ord æŒ‡å®šä¸º1ã€2 æ—¶è®¡ç®—L1ã€L2 èŒƒæ•°ï¼ŒæŒ‡å®šä¸ºnp.inf æ—¶è®¡ç®—âˆ âˆ’èŒƒæ•°ã€‚

### æœ€å€¼

- `tf.reduce_max(x, axis)`

- `tf.reduce_min(x, axis)`

### å‡å€¼

`tf.reduce_mean(x, axis)`

### å’Œ

`tf.reduce_sum(x, axis)`	æ±‚è§£å¼ é‡åœ¨axis è½´ä¸Šæ‰€æœ‰ç‰¹å¾çš„å’Œ



**å½“ä¸æŒ‡å®šaxis å‚æ•°æ—¶ï¼Œtf.reduce_*å‡½æ•°ä¼šæ±‚è§£å‡ºå…¨å±€å…ƒç´ çš„æœ€å¤§ã€æœ€å°ã€å‡å€¼ã€å’Œç­‰æ•°æ®**

### æœ€å€¼ç´¢å¼•

é€šè¿‡ `tf.argmax(x, axis)`å’Œ`tf.argmin(x, axis)`å¯ä»¥æ±‚è§£åœ¨axis è½´ä¸Šï¼Œx çš„æœ€å¤§å€¼ã€æœ€å°å€¼æ‰€åœ¨çš„**ç´¢å¼•å·**

```python
a.shape = [4, 10]

tf.argmax(a).shape = [10]
tf.argmax(a) = array([3, 3, 3, 3, 3, 3, 3, 2, 1, 0])

tf.argmin(a, axis=1).shape = [4]
tf.argmin(a) = array([9, 8, 7, 6])

# ç»“åˆä¸‹é¢çš„çŸ©é˜µå¥½ç†è§£
```

$$
\begin{bmatrix}
0&1&2&3&4&5&6&7&8&9\\
1&2&3&4&5&6&7&8&9&0\\
2&3&4&5&6&7&8&9&0&1\\
3&4&5&6&7&8&9&0&1&2\\
\end{bmatrix}
$$

### æ¯”è¾ƒ

`tf.equal(a, b)`

```python
# å‡è®¾
a = tf.constant([1, 2, 3, 3, 5])
b = tf.range(5)		# b = [1, 2, 3, 4, 5]

# æ¯”è¾ƒ
tf.equal(a, b)
<tf.Tensor: shape=(5,), dtype=bool, numpy=array([False, False, False, True, False])>
# è¿”å›
[False, False, False, True, False] ç›¸å½“äº [0, 0, 0, 1, 0]
```

ç”¨æ¥åšç²¾ç¡®åº¦è®¡ç®—

å‡è®¾æ ·æœ¬é¢„æµ‹ç»“æœa=$\begin{bmatrix}
0.1&0.2&0.7\\
0.9&0.05&0.05\\
\end{bmatrix}$ï¼Œåˆ™`pred = argmax(a, axis=1)`çš„ç»“æœä¸º[2ï¼Œ 0]ï¼Œæ ·æœ¬å®é™…å€¼yä¸º[2, 1]

```python
# æ¯”è¾ƒé¢„æµ‹å€¼å’Œå®é™…å€¼çš„è¯¯å·®
tf.equal(pred, y)
# å¾—åˆ° [True, False]å³[1, 0]
# å°†æ¯”è¾ƒç»“æœçš„æ•°æ®ç›¸åŠ 
correct = tf.reduce_sum(tf.cast(tf.equal(pred, y), dtype=tf.int32))
# å¾—åˆ° correct = 1
# ç„¶åé™¤ä»¥æ ·æœ¬æ•°é‡2
correct / 2 = 0.5
# æ‰€ä»¥ç²¾ç¡®åº¦ä¸º0.5
```

### å»é™¤é‡å¤

`tf.unique`



------

## å¼ é‡æ’åº

### éšæœºæ‰“æ•£

`tf.random.shuffle`

### Sort/argsort

`a = tf.random.shuffle(tf.range(5))`	=>  tf.Tensor([4 2 1 3 0], shape=(5,), dtype=int32)

- `tf.sort`	è¿”å›æ’åºåçš„ç»“æœ

```python
tf.sort(a, direction='DESCENDING')
<tf.Tensor: shape=(5,), dtype=int32, numpy=array([4, 3, 2, 1, 0])>
```

- `tf.argsort`	è¿”å›æ’åºçš„ç´¢å¼•ï¼Œæ¯”å¦‚è¿™ä¸ªç´¢å¼•0å¯¹åº”aä¸­çš„å€¼4ï¼›ç´¢å¼•3å¯¹åº”aä¸­çš„å€¼3ï¼›ç´¢å¼•1å¯¹åº”aä¸­çš„å€¼2...

```python
tf.argsort(a, direction='DESCENDING')
<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 3, 1, 2, 4])>
```

*è¿™é‡Œéƒ½æ˜¯é»˜è®¤å¯¹å·¦åä¸€ä¸ªè½´è¿›è¡Œæ’åº*

### Top_k

è¿”å›å‰**k**ä¸ªæ’åºç»“æœ

`res = tf.matg.top_k(a, k)`ï¼Œaæ˜¯å¾…æ’åºçš„å¼ é‡ï¼Œkæ˜¯å‰kä¸ªç»“æœ

`res.indices`è¿”å›å‰kä¸ªçš„ç´¢å¼•

`res.values`è¿”å›å‰kä¸ªçš„å€¼

## å¡«å……ä¸å¤åˆ¶

### å¡«å……

`tf.pad(a, padding)` aä¸ºå¾…å¡«å……çš„tensorï¼Œå‚æ•°paddings æ˜¯åŒ…å«äº†å¤šä¸ª**[** *Left Padding*, *Right Padding* **]**çš„åµŒå¥—æ–¹æ¡ˆListã€‚

å¦‚[[0,0], [2,1], [1,2]]è¡¨ç¤ºç¬¬ä¸€ä¸ªç»´åº¦ä¸å¡«å……ï¼Œç¬¬äºŒä¸ªç»´åº¦å·¦è¾¹(èµ·å§‹å¤„)å¡«å……ä¸¤ä¸ªå•å…ƒï¼Œå³è¾¹(ç»“æŸå¤„)å¡«å……ä¸€ä¸ªå•å…ƒï¼Œç¬¬ä¸‰ä¸ªç»´åº¦å·¦è¾¹å¡«å……ä¸€ä¸ªå•å…ƒï¼Œå³è¾¹å¡«å……ä¸¤ä¸ªå•å…ƒã€‚

![image-20210806171616867](https://gitee.com/ihunzi/images/raw/master/blog/image-20210806171616867.png)

### å¤åˆ¶

`tf.tile(a, copy_list)`	aä¸ºå¾…æ“ä½œå¼ é‡ï¼Œcopy_listä¸ºæ¯ä¸ªç»´åº¦éœ€è¦å¤åˆ¶çš„æ¬¡æ•°çš„List

æ¯”å¦‚

`tf.tile(a, [1, 2])`

æŠŠaåœ¨ç¬¬ä¸€ä¸ªç»´åº¦ä¿æŒä¸å˜ï¼Œç¬¬äºŒä¸ªç»´åº¦å˜æˆ2å€

![image-20210806173003189](https://gitee.com/ihunzi/images/raw/master/blog/image-20210806173003189.png)

------

## å¼ é‡é™å¹…

### $[a, +\infty)$â€‹â€‹â€‹

`tf.maximum(x, a)`

### $(-\infty, a]$â€‹â€‹â€‹

`tf.minimum(x, a)`

### $[a, b]$â€‹â€‹

`tf.clip_by_value(x, a, b)`



------

## é«˜çº§æ“ä½œ

- `tf.where(tensor)`

whereæ˜¯ä¸€ä¸ªæŸ¥è¯¢å…ƒç´ ä¸ºtrueçš„æ–¹æ³•

![image-20210807101417030](https://gitee.com/ihunzi/images/raw/master/blog/image-20210807101417030.png)

![image-20210807101635394](https://gitee.com/ihunzi/images/raw/master/blog/image-20210807101635394.png)

- `scatter_nd(indices, updates, shape)`

![image-20210807101932728](https://gitee.com/ihunzi/images/raw/master/blog/image-20210807101932728.png)

![image-20210807102145578](https://gitee.com/ihunzi/images/raw/master/blog/image-20210807102145578.png)

- `meshgrid`

é€šè¿‡ tf.meshgrid å‡½æ•°å¯ä»¥æ–¹ä¾¿åœ°ç”ŸæˆäºŒç»´ç½‘æ ¼çš„é‡‡æ ·ç‚¹åæ ‡ï¼Œæ–¹ä¾¿å¯è§†åŒ–ç­‰åº”ç”¨åœºåˆ



------

## ç»å…¸æ•°æ®é›†åŠ è½½

`keras.datasets`

é€šè¿‡ `datasets.xxx.load_data()`å‡½æ•°å³å¯å®ç°ç»å…¸æ•°æ®é›†çš„è‡ªåŠ¨åŠ è½½ï¼Œå…¶ä¸­xxx ä»£è¡¨å…·ä½“çš„æ•°æ®é›†åç§°ï¼Œå¦‚â€œCIFAR10â€ã€â€œMNISTâ€ã€‚TensorFlow ä¼šé»˜è®¤å°†æ•°æ®ç¼“å­˜åœ¨ç”¨æˆ·ç›®å½•ä¸‹çš„.keras/datasets æ–‡ä»¶å¤¹

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import datasets # å¯¼å…¥ç»å…¸æ•°æ®é›†åŠ è½½æ¨¡å—

# åŠ è½½MNIST æ•°æ®é›†
(x, y), (x_test, y_test) = datasets.mnist.load_data()
print('x:', x.shape, 'y:', y.shape, 'x test:', x_test.shape, 'y test:',y_test)

# è¿”å›æ•°ç»„çš„å½¢çŠ¶
Out [66]: x: (60000, 28, 28) y: (60000,) x test: (10000, 28, 28) y test: [7 2 1 ... 4 5 6]
```

`Dataset.from_tensor_slices`

æ•°æ®åŠ è½½è¿›å…¥å†…å­˜åï¼Œéœ€è¦è½¬æ¢æˆDataset å¯¹è±¡ï¼Œæ‰èƒ½åˆ©ç”¨TensorFlow æä¾›çš„å„ç§ä¾¿æ·åŠŸèƒ½ï¼Œæ¯”å¦‚ï¼šéšæœºæ‰“æ•£ï¼ˆ`Dataset.shuffle`ï¼‰ã€æ‰¹è®­ç»ƒï¼ˆ`Dataset.batch`ï¼‰ç­‰ã€‚é€šè¿‡`Dataset.from_tensor_slices` å¯ä»¥å°†è®­ç»ƒéƒ¨åˆ†çš„æ•°æ®å›¾ç‰‡x å’Œæ ‡ç­¾y éƒ½è½¬æ¢æˆDataset å¯¹è±¡

```python
train_db = tf.data.Dataset.from_tensor_slices((x, y)) # æ„å»ºDataset å¯¹è±¡
```

å°†æ•°æ®è½¬æ¢æˆDataset å¯¹è±¡åï¼Œä¸€èˆ¬éœ€è¦å†æ·»åŠ ä¸€ç³»åˆ—çš„æ•°æ®é›†æ ‡å‡†å¤„ç†æ­¥éª¤ï¼Œå¦‚éšæœºæ‰“æ•£ã€é¢„å¤„ç†ã€æŒ‰æ‰¹è£…è½½ç­‰ã€‚

### éšæœºæ‰“æ•£

é€šè¿‡ `Dataset.shuffle(buffer_size)`å·¥å…·å¯ä»¥è®¾ç½®Dataset å¯¹è±¡éšæœºæ‰“æ•£æ•°æ®ä¹‹é—´çš„é¡ºåºï¼Œé˜²æ­¢æ¯æ¬¡è®­ç»ƒæ—¶æ•°æ®æŒ‰å›ºå®šé¡ºåºäº§ç”Ÿï¼Œä»è€Œä½¿å¾—æ¨¡å‹å°è¯•â€œè®°å¿†â€ä½æ ‡ç­¾ä¿¡æ¯ï¼Œä»£ç å®ç°å¦‚ä¸‹ï¼š

```py
train_db = train_db.shuffle(10000) # éšæœºæ‰“æ•£æ ·æœ¬ï¼Œä¸ä¼šæ‰“ä¹±æ ·æœ¬ä¸æ ‡ç­¾æ˜ å°„å…³ç³»
```

å…¶ä¸­ï¼Œbuffer_size å‚æ•°æŒ‡å®šç¼“å†²æ± çš„å¤§å°ï¼Œä¸€èˆ¬è®¾ç½®ä¸ºä¸€ä¸ªè¾ƒå¤§çš„å¸¸æ•°å³å¯

### æ‰¹è®­ç»ƒ

ä¸ºäº†åˆ©ç”¨æ˜¾å¡çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼Œä¸€èˆ¬åœ¨ç½‘ç»œçš„è®¡ç®—è¿‡ç¨‹ä¸­ä¼šåŒæ—¶è®¡ç®—å¤šä¸ªæ ·æœ¬ï¼Œæˆ‘ä»¬æŠŠè¿™ç§è®­ç»ƒæ–¹å¼å«åšæ‰¹è®­ç»ƒï¼Œå…¶ä¸­ä¸€ä¸ªæ‰¹ä¸­æ ·æœ¬çš„æ•°é‡å«åš`Batch Size`ã€‚ä¸ºäº†ä¸€æ¬¡èƒ½å¤Ÿä»Dataset ä¸­äº§ç”ŸBatch Size æ•°é‡çš„æ ·æœ¬ï¼Œéœ€è¦è®¾ç½®Dataset ä¸ºæ‰¹è®­ç»ƒæ–¹å¼ï¼Œå®ç°å¦‚ä¸‹ï¼š

```python
train_db = train_db.batch(128) # è®¾ç½®æ‰¹è®­ç»ƒï¼Œbatch size ä¸º128
```

å…¶ä¸­128 ä¸ºBatch Size å‚æ•°ï¼Œå³ä¸€æ¬¡å¹¶è¡Œè®¡ç®—128 ä¸ªæ ·æœ¬çš„æ•°æ®ã€‚Batch Size ä¸€èˆ¬æ ¹æ®ç”¨æˆ·çš„GPU æ˜¾å­˜èµ„æºæ¥è®¾ç½®ï¼Œå½“æ˜¾å­˜ä¸è¶³æ—¶ï¼Œå¯ä»¥é€‚é‡å‡å°‘Batch Size æ¥å‡å°‘ç®—æ³•çš„æ˜¾å­˜ä½¿ç”¨é‡ã€‚

### é¢„å¤„ç†

ä» keras.datasets ä¸­åŠ è½½çš„æ•°æ®é›†çš„æ ¼å¼å¤§éƒ¨åˆ†æƒ…å†µéƒ½ä¸èƒ½ç›´æ¥æ»¡è¶³æ¨¡å‹çš„è¾“å…¥è¦æ±‚ï¼Œå› æ­¤éœ€è¦æ ¹æ®**ç”¨æˆ·çš„é€»è¾‘è‡ªè¡Œå®ç°**é¢„å¤„ç†æ­¥éª¤ã€‚Dataset å¯¹è±¡é€šè¿‡æä¾›`map(func)`å·¥å…·å‡½æ•°ï¼Œå¯ä»¥éå¸¸æ–¹ä¾¿åœ°è°ƒç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„é¢„å¤„ç†é€»è¾‘ï¼Œå®ƒå®ç°åœ¨func å‡½æ•°é‡Œã€‚ä¾‹å¦‚ï¼Œä¸‹æ–¹ä»£ç è°ƒç”¨åä¸ºpreprocess çš„å‡½æ•°å®Œæˆæ¯ä¸ªæ ·æœ¬çš„é¢„å¤„ç†ï¼š

```python
# é¢„å¤„ç†å‡½æ•°å®ç°åœ¨preprocess å‡½æ•°ä¸­ï¼Œä¼ å…¥å‡½æ•°åå³å¯
train_db = train_db.map(preprocess)
```

è€ƒè™‘ MNIST æ‰‹å†™æ•°å­—å›¾ç‰‡ï¼Œä»keras.datasets ä¸­ç».batch()ååŠ è½½çš„å›¾ç‰‡x shape ä¸º[ğ‘, 28,28]ï¼Œåƒç´ ä½¿ç”¨0~255 çš„æ•´å‹è¡¨ç¤ºï¼›æ ‡ç­¾shape ä¸º[ğ‘]ï¼Œå³é‡‡æ ·æ•°å­—ç¼–ç æ–¹å¼ã€‚å®é™…çš„ç¥ç»ç½‘ç»œè¾“å…¥ï¼Œä¸€èˆ¬éœ€è¦å°†å›¾ç‰‡æ•°æ®æ ‡å‡†åŒ–åˆ°[0,1]æˆ–[âˆ’1,1]ç­‰0 é™„è¿‘åŒºé—´ï¼ŒåŒæ—¶æ ¹æ®ç½‘ç»œçš„è®¾ç½®ï¼Œéœ€è¦å°†shape ä¸º[28,28]çš„è¾“å…¥è§†å›¾è°ƒæ•´ä¸ºåˆæ³•çš„æ ¼å¼ï¼›å¯¹äºæ ‡ç­¾ä¿¡æ¯ï¼Œå¯ä»¥é€‰æ‹©åœ¨é¢„å¤„ç†æ—¶è¿›è¡ŒOne-hot ç¼–ç ï¼Œä¹Ÿå¯ä»¥åœ¨è®¡ç®—è¯¯å·®æ—¶è¿›è¡ŒOne-hot ç¼–ç ã€‚

æˆ‘ä»¬å°†MNIST å›¾ç‰‡æ•°æ®æ˜ å°„åˆ°ğ‘¥ âˆˆ [0,1]åŒºé—´ï¼Œè§†å›¾è°ƒæ•´ä¸º[ğ‘, 28 âˆ— 28]ï¼›å¯¹äºæ ‡ç­¾æ•°æ®ï¼Œæˆ‘ä»¬é€‰æ‹©åœ¨é¢„å¤„ç†å‡½æ•°é‡Œé¢è¿›è¡ŒOne-hot ç¼–ç ã€‚preprocess å‡½æ•°å®ç°å¦‚ä¸‹ï¼š

```python
def preprocess(x, y): # è‡ªå®šä¹‰çš„é¢„å¤„ç†å‡½æ•°
    # è°ƒç”¨æ­¤å‡½æ•°æ—¶ä¼šè‡ªåŠ¨ä¼ å…¥x,y å¯¹è±¡ï¼Œshape ä¸º[b, 28, 28], [b]
    # æ ‡å‡†åŒ–åˆ°0~1
    x = tf.cast(x, dtype=tf.float32) / 255.
    x = tf.reshape(x, [-1, 28*28]) # æ‰“å¹³
    y = tf.cast(y, dtype=tf.int32) # è½¬æˆæ•´å‹å¼ é‡
    y = tf.one_hot(y, depth=10) # one-hot ç¼–ç 
    # è¿”å›çš„x,y å°†æ›¿æ¢ä¼ å…¥çš„x,y å‚æ•°ï¼Œä»è€Œå®ç°æ•°æ®çš„é¢„å¤„ç†åŠŸèƒ½
    return x,y
```

### å¾ªç¯è®­ç»ƒ

å¯¹äº Dataset å¯¹è±¡ï¼Œåœ¨ä½¿ç”¨æ—¶å¯ä»¥é€šè¿‡

```python
for step, (x,y) in enumerate(train_db): # è¿­ä»£æ•°æ®é›†å¯¹è±¡ï¼Œå¸¦step å‚æ•°
```

æˆ–è€…

```python
for x,y in train_db: # è¿­ä»£æ•°æ®é›†å¯¹è±¡
```

æ–¹å¼è¿›è¡Œè¿­ä»£ï¼Œæ¯æ¬¡è¿”å›çš„x å’Œy å¯¹è±¡å³ä¸ºæ‰¹é‡æ ·æœ¬å’Œæ ‡ç­¾ã€‚å½“å¯¹train_db çš„æ‰€æœ‰æ ·æœ¬å®Œæˆä¸€æ¬¡è¿­ä»£åï¼Œfor å¾ªç¯ç»ˆæ­¢é€€å‡ºã€‚è¿™æ ·**å®Œæˆä¸€ä¸ªBatch çš„æ•°æ®è®­ç»ƒï¼Œå«åšä¸€ä¸ªStep**ï¼›é€šè¿‡**å¤šä¸ªstep æ¥å®Œæˆæ•´ä¸ªè®­ç»ƒé›†çš„ä¸€æ¬¡è¿­ä»£ï¼Œå«åšä¸€ä¸ªEpoch**ã€‚åœ¨å®é™…è®­ç»ƒæ—¶ï¼Œé€šå¸¸éœ€è¦å¯¹æ•°æ®é›†**è¿­ä»£å¤šä¸ªEpoch æ‰èƒ½å–å¾—è¾ƒå¥½åœ°è®­ç»ƒæ•ˆæœ**ã€‚ä¾‹å¦‚ï¼Œå›ºå®šè®­ç»ƒ20 ä¸ªEpochï¼Œå®ç°å¦‚ä¸‹ï¼š

```python
for epoch in range(20): # è®­ç»ƒEpoch æ•°
    for step, (x,y) in enumerate(train_db): # è¿­ä»£Step æ•°
        # training...
```

æ­¤å¤–ï¼Œä¹Ÿå¯ä»¥é€šè¿‡è®¾ç½®Dataset å¯¹è±¡ï¼Œä½¿å¾—æ•°æ®é›†å¯¹è±¡å†…éƒ¨éå†å¤šæ¬¡æ‰ä¼šé€€å‡ºï¼Œå®ç°å¦‚ä¸‹:

```python
train_db = train_db.repeat(20) # æ•°æ®é›†è¿­ä»£20 éæ‰ç»ˆæ­¢
```

ä¸Šè¿°ä»£ç ä½¿å¾—`for x,y in train_db` å¾ªç¯è¿­ä»£20 ä¸ªepoch æ‰ä¼šé€€å‡ºã€‚ä¸ç®¡ä½¿ç”¨ä¸Šè¿°å“ªç§æ–¹å¼ï¼Œéƒ½èƒ½å–å¾—ä¸€æ ·çš„æ•ˆæœã€‚

